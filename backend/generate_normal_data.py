"""
ì •ìƒ ë°ì´í„° ìƒì„± ìŠ¤í¬ë¦½íŠ¸

ì´ìƒí–‰ë™ ë°ì´í„°ë§Œ ìˆì„ ë•Œ ì •ìƒ ë°ì´í„°ë¥¼ ìƒì„±í•˜ëŠ” ë°©ë²•:
1. ë°°ê²½ ì˜ìƒ ìƒì„± (ì‚¬ëŒ ì—†ëŠ” ë¹ˆ í™”ë©´)
2. ì´ìƒí–‰ë™ ì˜ìƒì—ì„œ ì •ìƒ ë¶€ë¶„ë§Œ ì¶”ì¶œ
3. ì›¹ìº ìœ¼ë¡œ ì •ìƒ í™œë™ ì´¬ì˜
4. ê³µê°œ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ

ì‚¬ìš©ë²•:
    python generate_normal_data.py --method [background|webcam|extract]
"""

import cv2
import numpy as np
from pathlib import Path
import argparse
import time
from datetime import datetime

class NormalDataGenerator:
    def __init__(self, output_dir='data/raw/normal'):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        self.width = 640
        self.height = 480
        self.fps = 30
        self.duration = 5
    
    def generate_background_videos(self, num_videos=50):
        """
        ë°©ë²• 1: ë°°ê²½ ì˜ìƒ ìƒì„± (ì‚¬ëŒ ì—†ëŠ” ë¹ˆ í™”ë©´)
        - ì´ìƒí–‰ë™ì´ ì—†ëŠ” ë¹ˆ ë°°ê²½ì„ ì •ìƒìœ¼ë¡œ ê°„ì£¼
        """
        print("\n" + "="*60)
        print("ğŸ“¹ ë°°ê²½ ì˜ìƒ ìƒì„± ì¤‘...")
        print("="*60)
        print(f"ìƒì„±í•  ì˜ìƒ ìˆ˜: {num_videos}ê°œ")
        print("ì„¤ëª…: ì‚¬ëŒì´ ì—†ê±°ë‚˜ ì•„ë¬´ ì¼ë„ ì¼ì–´ë‚˜ì§€ ì•ŠëŠ” ì •ìƒ ìƒíƒœ")
        print()
        
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        total_frames = self.fps * self.duration
        
        backgrounds = [
            ('empty_store', self._create_empty_store),
            ('quiet_corridor', self._create_quiet_corridor),
            ('static_shelves', self._create_static_shelves),
        ]
        
        for i in range(num_videos):
            bg_name, bg_func = backgrounds[i % len(backgrounds)]
            output_path = self.output_dir / f"normal_bg_{i:03d}_{bg_name}.mp4"
            
            out = cv2.VideoWriter(str(output_path), fourcc, self.fps, 
                                 (self.width, self.height))
            
            for frame_num in range(total_frames):
                frame = bg_func(frame_num)
                
                # ì•½ê°„ì˜ ë…¸ì´ì¦ˆ ì¶”ê°€ (ì‹¤ì œ ì¹´ë©”ë¼ ëŠë‚Œ)
                noise = np.random.normal(0, 5, frame.shape).astype(np.int16)
                frame = np.clip(frame.astype(np.int16) + noise, 0, 255).astype(np.uint8)
                
                # íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€
                timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                cv2.putText(frame, timestamp, (10, self.height - 20),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (100, 100, 100), 1)
                
                out.write(frame)
            
            out.release()
            
            if (i + 1) % 10 == 0:
                print(f"  ì§„í–‰: {i + 1}/{num_videos}")
        
        print(f"\nâœ… {num_videos}ê°œ ë°°ê²½ ì˜ìƒ ìƒì„± ì™„ë£Œ!")
        print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {self.output_dir}")
    
    def _create_empty_store(self, frame_num):
        """ë¹ˆ ê°€ê²Œ ë°°ê²½"""
        frame = np.ones((self.height, self.width, 3), dtype=np.uint8) * 220
        
        # ë°”ë‹¥ íƒ€ì¼
        for i in range(0, self.width, 50):
            cv2.line(frame, (i, 0), (i, self.height), (200, 200, 200), 1)
        for i in range(0, self.height, 50):
            cv2.line(frame, (0, i), (self.width, i), (200, 200, 200), 1)
        
        # ì•½ê°„ì˜ ì›€ì§ì„ (ì¡°ëª… ë³€í™”)
        brightness = 220 + int(5 * np.sin(frame_num * 0.05))
        frame = np.clip(frame.astype(np.int16) + (brightness - 220), 0, 255).astype(np.uint8)
        
        return frame
    
    def _create_quiet_corridor(self, frame_num):
        """ì¡°ìš©í•œ ë³µë„"""
        frame = np.ones((self.height, self.width, 3), dtype=np.uint8) * 180
        
        # ë³µë„ ì›ê·¼
        pts1 = np.array([[50, 100], [self.width-50, 100], 
                        [self.width-20, self.height-50], [20, self.height-50]], np.int32)
        cv2.fillPoly(frame, [pts1], (200, 200, 210))
        
        return frame
    
    def _create_static_shelves(self, frame_num):
        """ì •ì ì¸ ì„ ë°˜"""
        frame = np.ones((self.height, self.width, 3), dtype=np.uint8) * 190
        
        # ì„ ë°˜
        for i in range(3):
            y = 100 + i * 100
            cv2.rectangle(frame, (50, y), (self.width-50, y+60), (150, 120, 100), -1)
            cv2.rectangle(frame, (50, y), (self.width-50, y+60), (100, 80, 60), 2)
        
        return frame
    
    def record_from_webcam(self, num_videos=20):
        """
        ë°©ë²• 2: ì›¹ìº ìœ¼ë¡œ ì •ìƒ í™œë™ ì´¬ì˜
        - ì‹¤ì œ ì‚¬ëŒì´ í‰ë²”í•˜ê²Œ ê±·ê±°ë‚˜ ë¬¼ê±´ì„ ë³´ëŠ” ë“±ì˜ ì •ìƒ í™œë™
        """
        print("\n" + "="*60)
        print("ğŸ“¹ ì›¹ìº ìœ¼ë¡œ ì •ìƒ í™œë™ ì´¬ì˜")
        print("="*60)
        print("ë…¹í™”í•  ì˜ìƒ ìˆ˜:", num_videos)
        print("\nì§€ì¹¨:")
        print("  - í‰ë²”í•˜ê²Œ ê±·ê¸°")
        print("  - ë¬¼ê±´ ë³´ê¸°")
        print("  - ì„œì„œ ëŒ€ê¸°í•˜ê¸°")
        print("  - ì²œì²œíˆ ì´ë™í•˜ê¸°")
        print("\nê° ì˜ìƒì€ 5ì´ˆì”© ë…¹í™”ë©ë‹ˆë‹¤.")
        print("ì¤€ë¹„ë˜ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")
        input()
        
        cap = cv2.VideoCapture(0)
        
        if not cap.isOpened():
            print("âŒ ì›¹ìº ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
            return
        
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        
        for i in range(num_videos):
            print(f"\nğŸ“¹ ì˜ìƒ {i+1}/{num_videos} ë…¹í™” ì¤‘...")
            print("3ì´ˆ í›„ ë…¹í™” ì‹œì‘...")
            
            # ì¹´ìš´íŠ¸ë‹¤ìš´
            for countdown in range(3, 0, -1):
                ret, frame = cap.read()
                if ret:
                    frame = cv2.resize(frame, (self.width, self.height))
                    cv2.putText(frame, str(countdown), (self.width//2-50, self.height//2),
                               cv2.FONT_HERSHEY_SIMPLEX, 3, (0, 255, 0), 5)
                    cv2.imshow('Recording', frame)
                    cv2.waitKey(1000)
            
            # ë…¹í™” ì‹œì‘
            output_path = self.output_dir / f"normal_webcam_{i:03d}.mp4"
            out = cv2.VideoWriter(str(output_path), fourcc, self.fps, 
                                 (self.width, self.height))
            
            start_time = time.time()
            frame_count = 0
            
            while (time.time() - start_time) < self.duration:
                ret, frame = cap.read()
                if not ret:
                    break
                
                frame = cv2.resize(frame, (self.width, self.height))
                
                # ë…¹í™” ì¤‘ í‘œì‹œ
                remaining = self.duration - (time.time() - start_time)
                cv2.circle(frame, (20, 20), 10, (0, 0, 255), -1)
                cv2.putText(frame, f'REC {remaining:.1f}s', (40, 30),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
                
                out.write(frame)
                cv2.imshow('Recording', frame)
                cv2.waitKey(1)
                frame_count += 1
            
            out.release()
            print(f"âœ… ì˜ìƒ {i+1} ì €ì¥ ì™„ë£Œ ({frame_count} í”„ë ˆì„)")
            
            if i < num_videos - 1:
                print("ë‹¤ìŒ ì´¬ì˜ ì¤€ë¹„... (Enterë¥¼ ëˆŒëŸ¬ ê³„ì†)")
                input()
        
        cap.release()
        cv2.destroyAllWindows()
        
        print(f"\nâœ… ì´ {num_videos}ê°œ ì˜ìƒ ë…¹í™” ì™„ë£Œ!")
        print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {self.output_dir}")
    
    def extract_from_abnormal_videos(self, abnormal_dir='data/raw', threshold_duration=2.0):
        """
        ë°©ë²• 3: ì´ìƒí–‰ë™ ì˜ìƒì—ì„œ ì •ìƒ ë¶€ë¶„ ì¶”ì¶œ
        - ì´ìƒí–‰ë™ì´ ì‹œì‘ë˜ê¸° ì „ ë¶€ë¶„
        - ì´ìƒí–‰ë™ì´ ëë‚œ í›„ ë¶€ë¶„
        """
        print("\n" + "="*60)
        print("ğŸ“¹ ì´ìƒí–‰ë™ ì˜ìƒì—ì„œ ì •ìƒ ë¶€ë¶„ ì¶”ì¶œ")
        print("="*60)
        print(f"ëŒ€ìƒ í´ë”: {abnormal_dir}")
        print(f"ì¶”ì¶œ ê¸°ì¤€: ì›€ì§ì„ì´ ì ì€ {threshold_duration}ì´ˆ êµ¬ê°„")
        print()
        
        abnormal_dir = Path(abnormal_dir)
        video_count = 0
        extracted_count = 0
        
        # ì´ìƒí–‰ë™ í´ë”ë“¤ ìˆœíšŒ
        for class_dir in abnormal_dir.iterdir():
            if not class_dir.is_dir() or class_dir.name == 'normal':
                continue
            
            print(f"ğŸ“‚ {class_dir.name} í´ë” ì²˜ë¦¬ ì¤‘...")
            
            for video_path in class_dir.glob('*.mp4'):
                video_count += 1
                
                # ì˜ìƒì˜ ì•ë¶€ë¶„ê³¼ ë’·ë¶€ë¶„ì—ì„œ ì •ìƒ êµ¬ê°„ ì¶”ì¶œ
                segments = self._extract_calm_segments(video_path, threshold_duration)
                
                for idx, segment in enumerate(segments):
                    output_path = self.output_dir / f"normal_extracted_{class_dir.name}_{video_path.stem}_{idx}.mp4"
                    if self._save_segment(video_path, segment, output_path):
                        extracted_count += 1
        
        print(f"\nâœ… {video_count}ê°œ ì˜ìƒì—ì„œ {extracted_count}ê°œ ì •ìƒ êµ¬ê°„ ì¶”ì¶œ ì™„ë£Œ!")
        print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {self.output_dir}")
    
    def _extract_calm_segments(self, video_path, duration):
        """ì›€ì§ì„ì´ ì ì€ êµ¬ê°„ ì°¾ê¸°"""
        cap = cv2.VideoCapture(str(video_path))
        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        if total_frames < fps * duration:
            cap.release()
            return []
        
        # ê°„ë‹¨í•œ ë°©ë²•: ì˜ìƒì˜ ì²˜ìŒ 30%ì™€ ë§ˆì§€ë§‰ 30%ì—ì„œ ì¶”ì¶œ
        segments = []
        
        # ì•ë¶€ë¶„
        if total_frames * 0.3 > fps * duration:
            segments.append((0, int(fps * duration)))
        
        # ë’·ë¶€ë¶„
        end_start = total_frames - int(fps * duration)
        if end_start > total_frames * 0.7:
            segments.append((end_start, total_frames))
        
        cap.release()
        return segments
    
    def _save_segment(self, video_path, segment, output_path):
        """ë¹„ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ ì €ì¥"""
        start_frame, end_frame = segment
        
        cap = cv2.VideoCapture(str(video_path))
        fps = cap.get(cv2.CAP_PROP_FPS)
        
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(str(output_path), fourcc, fps, 
                             (self.width, self.height))
        
        cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)
        
        for _ in range(end_frame - start_frame):
            ret, frame = cap.read()
            if not ret:
                break
            frame = cv2.resize(frame, (self.width, self.height))
            out.write(frame)
        
        cap.release()
        out.release()
        
        return True


def main():
    parser = argparse.ArgumentParser(description='ì •ìƒ ë°ì´í„° ìƒì„±')
    parser.add_argument('--method', type=str, default='background',
                       choices=['background', 'webcam', 'extract', 'all'],
                       help='ìƒì„± ë°©ë²• ì„ íƒ')
    parser.add_argument('--num', type=int, default=50,
                       help='ìƒì„±í•  ì˜ìƒ ìˆ˜')
    
    args = parser.parse_args()
    
    generator = NormalDataGenerator()
    
    print("="*60)
    print("ğŸ¬ ì •ìƒ ë°ì´í„° ìƒì„±ê¸°")
    print("="*60)
    print("\nğŸ’¡ ì´ìƒí–‰ë™ ë°ì´í„°ë§Œ ìˆì„ ë•Œ ì •ìƒ ë°ì´í„°ë¥¼ ë§Œë“œëŠ” ë„êµ¬ì…ë‹ˆë‹¤.")
    print()
    
    if args.method == 'background' or args.method == 'all':
        print("\n[ë°©ë²• 1] ë°°ê²½ ì˜ìƒ ìƒì„±")
        print("  ì¥ì : ë¹ ë¥´ê³  ê°„í¸, ëŒ€ëŸ‰ ìƒì„± ê°€ëŠ¥")
        print("  ë‹¨ì : ì‹¤ì œ ì‚¬ëŒ í™œë™ì´ ì—†ìŒ")
        generator.generate_background_videos(num_videos=args.num)
    
    if args.method == 'webcam' or args.method == 'all':
        print("\n[ë°©ë²• 2] ì›¹ìº  ì´¬ì˜")
        print("  ì¥ì : ì‹¤ì œ ì •ìƒ í™œë™ ë°ì´í„°")
        print("  ë‹¨ì : ì‹œê°„ ì†Œìš”, ìˆ˜ë™ ì‘ì—… í•„ìš”")
        response = input("\nì›¹ìº  ì´¬ì˜ì„ ì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ")
        if response.lower() == 'y':
            generator.record_from_webcam(num_videos=20)
    
    if args.method == 'extract' or args.method == 'all':
        print("\n[ë°©ë²• 3] ì´ìƒí–‰ë™ ì˜ìƒì—ì„œ ì •ìƒ êµ¬ê°„ ì¶”ì¶œ")
        print("  ì¥ì : ê¸°ì¡´ ë°ì´í„° í™œìš©")
        print("  ë‹¨ì : ì •ìƒ êµ¬ê°„ì´ ì¶©ë¶„í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ")
        response = input("\nì´ìƒí–‰ë™ ì˜ìƒì—ì„œ ì¶”ì¶œí•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ")
        if response.lower() == 'y':
            generator.extract_from_abnormal_videos()
    
    print("\n" + "="*60)
    print("âœ¨ ì™„ë£Œ!")
    print("="*60)
    print(f"\nğŸ“ ìƒì„±ëœ ì •ìƒ ë°ì´í„°: data/raw/normal/")
    print("\në‹¤ìŒ ë‹¨ê³„:")
    print("  python preprocess_data.py")
    print("  python train_model.py")


if __name__ == '__main__':
    main()
