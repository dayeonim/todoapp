"""
ì •ìƒ ë°ì´í„° ì—†ì´ í•™ìŠµí•˜ëŠ” ëª¨ë¸

ì ‘ê·¼ë²•: Multi-label Classification
- "ì •ìƒ" í´ë˜ìŠ¤ ì—†ì´ 8ê°€ì§€ ì´ìƒí–‰ë™ë§Œ ë¶„ë¥˜
- ëª¨ë“  ì´ìƒí–‰ë™ì— í•´ë‹¹í•˜ì§€ ì•Šìœ¼ë©´ "ì •ìƒ"ìœ¼ë¡œ ê°„ì£¼
- ì‹ ë¢°ë„ ì„ê³„ê°’ì„ ì„¤ì •í•˜ì—¬ ë¶ˆí™•ì‹¤í•œ ê²½ìš° "ì •ìƒ"ìœ¼ë¡œ ì²˜ë¦¬

ì‚¬ìš©ë²•:
    python train_model_no_normal.py
"""

import os
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from pathlib import Path
import json
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime

class AbnormalOnlyModelTrainer:
    def __init__(self, 
                 data_dir='data/processed',
                 model_save_dir='models',
                 input_shape=(16, 224, 224, 3),
                 batch_size=8,
                 epochs=50,
                 learning_rate=0.001,
                 confidence_threshold=0.6):
        
        self.data_dir = Path(data_dir)
        self.model_save_dir = Path(model_save_dir)
        self.model_save_dir.mkdir(parents=True, exist_ok=True)
        
        self.input_shape = input_shape
        self.batch_size = batch_size
        self.epochs = epochs
        self.learning_rate = learning_rate
        self.confidence_threshold = confidence_threshold
        
        # ì •ìƒ í´ë˜ìŠ¤ ì œì™¸ (ì´ìƒí–‰ë™ë§Œ)
        self.classes = [
            'fall', 'vandalism', 'fire', 'smoking',
            'abandonment', 'theft', 'assault', 'vulnerable'
        ]
        self.num_classes = len(self.classes)
        
        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}
    
    def load_data(self, split='train'):
        """ë°ì´í„° ë¡œë“œ (ì •ìƒ í´ë˜ìŠ¤ ì œì™¸)"""
        print(f"ğŸ“‚ {split} ë°ì´í„° ë¡œë“œ ì¤‘...")
        
        X = []
        y = []
        
        for class_name in self.classes:
            class_dir = self.data_dir / split / class_name
            
            if not class_dir.exists():
                print(f"  âš ï¸  í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {class_dir}")
                continue
            
            npy_files = list(class_dir.glob('*.npy'))
            
            print(f"  {class_name}: {len(npy_files)}ê°œ")
            
            for npy_file in npy_files:
                try:
                    frames = np.load(npy_file)
                    X.append(frames)
                    y.append(self.class_to_idx[class_name])
                except Exception as e:
                    print(f"    âš ï¸  ë¡œë“œ ì‹¤íŒ¨: {npy_file} - {e}")
        
        if not X:
            return None, None
        
        X = np.array(X)
        y = np.array(y)
        
        print(f"  âœ… {split}: X={X.shape}, y={y.shape}")
        
        return X, y
    
    def create_model(self):
        """3D CNN ëª¨ë¸ (ì´ìƒí–‰ë™ë§Œ ë¶„ë¥˜)"""
        print("\nğŸ—ï¸  ëª¨ë¸ êµ¬ì¶• ì¤‘...")
        print(f"   ì¶œë ¥ í´ë˜ìŠ¤: {self.num_classes}ê°œ (ì´ìƒí–‰ë™ë§Œ)")
        print(f"   ì‹ ë¢°ë„ ì„ê³„ê°’: {self.confidence_threshold}")
        
        model = keras.Sequential([
            # Conv3D Block 1
            layers.Conv3D(32, (3, 3, 3), activation='relu', 
                         padding='same', input_shape=self.input_shape),
            layers.MaxPooling3D((2, 2, 2)),
            layers.BatchNormalization(),
            layers.Dropout(0.25),
            
            # Conv3D Block 2
            layers.Conv3D(64, (3, 3, 3), activation='relu', padding='same'),
            layers.MaxPooling3D((2, 2, 2)),
            layers.BatchNormalization(),
            layers.Dropout(0.25),
            
            # Conv3D Block 3
            layers.Conv3D(128, (3, 3, 3), activation='relu', padding='same'),
            layers.MaxPooling3D((2, 2, 2)),
            layers.BatchNormalization(),
            layers.Dropout(0.3),
            
            # Conv3D Block 4
            layers.Conv3D(256, (3, 3, 3), activation='relu', padding='same'),
            layers.MaxPooling3D((1, 2, 2)),
            layers.BatchNormalization(),
            layers.Dropout(0.3),
            
            # Global pooling and Dense
            layers.GlobalAveragePooling3D(),
            layers.Dense(512, activation='relu'),
            layers.Dropout(0.5),
            layers.Dense(256, activation='relu'),
            layers.Dropout(0.5),
            
            # ì¶œë ¥ì¸µ (ì´ìƒí–‰ë™ë§Œ)
            layers.Dense(self.num_classes, activation='softmax')
        ])
        
        model.summary()
        
        return model
    
    def compile_model(self, model):
        """ëª¨ë¸ ì»´íŒŒì¼"""
        model.compile(
            optimizer=keras.optimizers.Adam(learning_rate=self.learning_rate),
            loss='sparse_categorical_crossentropy',
            metrics=['accuracy', keras.metrics.TopKCategoricalAccuracy(k=3, name='top3_acc')]
        )
        
        return model
    
    def get_callbacks(self):
        """í•™ìŠµ ì½œë°± ì„¤ì •"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        callbacks = [
            keras.callbacks.ModelCheckpoint(
                filepath=str(self.model_save_dir / f'model_no_normal_best_{timestamp}.h5'),
                monitor='val_accuracy',
                save_best_only=True,
                mode='max',
                verbose=1
            ),
            
            keras.callbacks.EarlyStopping(
                monitor='val_loss',
                patience=10,
                restore_best_weights=True,
                verbose=1
            ),
            
            keras.callbacks.ReduceLROnPlateau(
                monitor='val_loss',
                factor=0.5,
                patience=5,
                min_lr=1e-7,
                verbose=1
            ),
            
            keras.callbacks.TensorBoard(
                log_dir=f'logs/no_normal_{timestamp}',
                histogram_freq=1
            )
        ]
        
        return callbacks
    
    def plot_training_history(self, history, save_path):
        """í•™ìŠµ íˆìŠ¤í† ë¦¬ ì‹œê°í™”"""
        fig, axes = plt.subplots(1, 2, figsize=(15, 5))
        
        axes[0].plot(history.history['accuracy'], label='Train Accuracy')
        axes[0].plot(history.history['val_accuracy'], label='Val Accuracy')
        axes[0].set_title('Model Accuracy (Abnormal Only)')
        axes[0].set_xlabel('Epoch')
        axes[0].set_ylabel('Accuracy')
        axes[0].legend()
        axes[0].grid(True)
        
        axes[1].plot(history.history['loss'], label='Train Loss')
        axes[1].plot(history.history['val_loss'], label='Val Loss')
        axes[1].set_title('Model Loss')
        axes[1].set_xlabel('Epoch')
        axes[1].set_ylabel('Loss')
        axes[1].legend()
        axes[1].grid(True)
        
        plt.tight_layout()
        plt.savefig(save_path)
        print(f"  âœ… í•™ìŠµ íˆìŠ¤í† ë¦¬ ì €ì¥: {save_path}")
        plt.close()
    
    def evaluate_model(self, model, X_test, y_test):
        """ëª¨ë¸ í‰ê°€"""
        print("\nğŸ“Š ëª¨ë¸ í‰ê°€ ì¤‘...")
        
        y_pred_probs = model.predict(X_test)
        y_pred = np.argmax(y_pred_probs, axis=1)
        
        print("\n" + "="*60)
        print("Classification Report (Abnormal Actions Only)")
        print("="*60)
        print(classification_report(y_test, y_pred, target_names=self.classes))
        
        cm = confusion_matrix(y_test, y_pred)
        
        plt.figure(figsize=(12, 10))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Reds',
                   xticklabels=self.classes, yticklabels=self.classes)
        plt.title('Confusion Matrix (Abnormal Only)')
        plt.ylabel('True Label')
        plt.xlabel('Predicted Label')
        
        cm_path = self.model_save_dir / 'confusion_matrix_no_normal.png'
        plt.savefig(cm_path)
        print(f"\nâœ… Confusion Matrix ì €ì¥: {cm_path}")
        plt.close()
        
        # ì‹ ë¢°ë„ ë¶„ì„
        max_confidences = np.max(y_pred_probs, axis=1)
        print("\n" + "="*60)
        print("ì‹ ë¢°ë„ ë¶„ì„")
        print("="*60)
        print(f"í‰ê·  ì‹ ë¢°ë„: {np.mean(max_confidences):.3f}")
        print(f"ì¤‘ê°„ê°’ ì‹ ë¢°ë„: {np.median(max_confidences):.3f}")
        print(f"ì„ê³„ê°’ ì´í•˜ ë¹„ìœ¨: {np.mean(max_confidences < self.confidence_threshold)*100:.1f}%")
        print(f"\nğŸ’¡ ì„ê³„ê°’({self.confidence_threshold}) ì´í•˜ëŠ” 'ì •ìƒ'ìœ¼ë¡œ ë¶„ë¥˜ë©ë‹ˆë‹¤.")
        
        class_accuracy = cm.diagonal() / cm.sum(axis=1)
        
        print("\n" + "="*60)
        print("í´ë˜ìŠ¤ë³„ ì •í™•ë„")
        print("="*60)
        for cls, acc in zip(self.classes, class_accuracy):
            print(f"  {cls:12s}: {acc*100:6.2f}%")
        
        return {
            'classification_report': classification_report(y_test, y_pred, 
                                                          target_names=self.classes, 
                                                          output_dict=True),
            'confusion_matrix': cm.tolist(),
            'class_accuracy': {cls: float(acc) for cls, acc in zip(self.classes, class_accuracy)},
            'confidence_stats': {
                'mean': float(np.mean(max_confidences)),
                'median': float(np.median(max_confidences)),
                'threshold': self.confidence_threshold,
                'below_threshold_ratio': float(np.mean(max_confidences < self.confidence_threshold))
            }
        }
    
    def train(self):
        """ì „ì²´ í•™ìŠµ íŒŒì´í”„ë¼ì¸"""
        print("="*60)
        print("ğŸš€ ì´ìƒí–‰ë™ ì „ìš© ëª¨ë¸ í•™ìŠµ ì‹œì‘")
        print("="*60)
        print("\nğŸ’¡ ì •ìƒ ë°ì´í„° ì—†ì´ ì´ìƒí–‰ë™ë§Œ ë¶„ë¥˜í•©ë‹ˆë‹¤.")
        print(f"   ì‹ ë¢°ë„ê°€ {self.confidence_threshold} ë¯¸ë§Œì´ë©´ 'ì •ìƒ'ìœ¼ë¡œ ê°„ì£¼ë©ë‹ˆë‹¤.")
        print()
        
        # ë°ì´í„° ë¡œë“œ
        X_train, y_train = self.load_data('train')
        X_val, y_val = self.load_data('val')
        X_test, y_test = self.load_data('test')
        
        if X_train is None or X_val is None:
            print("\nâŒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!")
            print("ğŸ’¡ ë¨¼ì € preprocess_data.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”")
            return
        
        # ëª¨ë¸ ìƒì„± ë° ì»´íŒŒì¼
        model = self.create_model()
        model = self.compile_model(model)
        
        # í•™ìŠµ
        print(f"\nğŸ“ ëª¨ë¸ í•™ìŠµ ì‹œì‘")
        print("="*60)
        
        callbacks = self.get_callbacks()
        
        history = model.fit(
            X_train, y_train,
            validation_data=(X_val, y_val),
            batch_size=self.batch_size,
            epochs=self.epochs,
            callbacks=callbacks,
            verbose=1
        )
        
        # í•™ìŠµ íˆìŠ¤í† ë¦¬ ì €ì¥
        history_path = self.model_save_dir / 'training_history_no_normal.png'
        self.plot_training_history(history, history_path)
        
        # ìµœì¢… ëª¨ë¸ ì €ì¥
        final_model_path = self.model_save_dir / 'abnormal_detector_no_normal.h5'
        model.save(final_model_path)
        print(f"\nâœ… ìµœì¢… ëª¨ë¸ ì €ì¥: {final_model_path}")
        
        # ë©”íƒ€ë°ì´í„° ì €ì¥
        metadata = {
            'classes': self.classes,
            'num_classes': self.num_classes,
            'confidence_threshold': self.confidence_threshold,
            'input_shape': self.input_shape,
            'model_type': 'abnormal_only',
            'note': 'Predictions below confidence threshold are considered normal'
        }
        metadata_path = self.model_save_dir / 'model_metadata_no_normal.json'
        with open(metadata_path, 'w') as f:
            json.dump(metadata, f, indent=2)
        print(f"âœ… ë©”íƒ€ë°ì´í„° ì €ì¥: {metadata_path}")
        
        # í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ í‰ê°€
        if X_test is not None:
            eval_results = self.evaluate_model(model, X_test, y_test)
            
            results_path = self.model_save_dir / 'evaluation_results_no_normal.json'
            with open(results_path, 'w', encoding='utf-8') as f:
                json.dump(eval_results, f, indent=2, ensure_ascii=False)
            print(f"âœ… í‰ê°€ ê²°ê³¼ ì €ì¥: {results_path}")
        
        print("\n" + "="*60)
        print("âœ¨ í•™ìŠµ ì™„ë£Œ!")
        print("="*60)
        print(f"\nğŸ“ ëª¨ë¸ íŒŒì¼: {final_model_path}")
        print("\nâš ï¸  ì£¼ì˜ì‚¬í•­:")
        print(f"   - ì‹ ë¢°ë„ {self.confidence_threshold} ë¯¸ë§Œì€ 'ì •ìƒ'ìœ¼ë¡œ ì²˜ë¦¬")
        print("   - ì •ìƒ ë°ì´í„°ë¡œ ê²€ì¦ ê¶Œì¥")
        print("   - ì„ê³„ê°’ ì¡°ì •ìœ¼ë¡œ ë¯¼ê°ë„ ì¡°ì ˆ ê°€ëŠ¥")
        print("\në‹¤ìŒ ë‹¨ê³„:")
        print("   app.pyì—ì„œ ì´ ëª¨ë¸ ì‚¬ìš© (model_handler.py ìˆ˜ì •)")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    trainer = AbnormalOnlyModelTrainer(
        data_dir='data/processed',
        model_save_dir='models',
        batch_size=8,
        epochs=50,
        learning_rate=0.001,
        confidence_threshold=0.6  # ì´ ê°’ì„ ì¡°ì •í•˜ì—¬ ë¯¼ê°ë„ ë³€ê²½
    )
    
    trainer.train()


if __name__ == '__main__':
    main()
